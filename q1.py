# -*- coding: utf-8 -*-
"""Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P_2-VGTOHGIITqZHSr63Tx0uvDlmIPju
"""

from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, BatchNormalization
from keras.optimizers import SGD
from statistics import *

# load train and test dataset
def load_dataset():
    # load dataset
    (trainX, trainY), (testX, testY) = mnist.load_data()
    # reshape dataset to have a single channel
    #the pixel values are grayscale, the pixel dimension is set to 1.
    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
    testX = testX.reshape((testX.shape[0], 28, 28, 1))
    # one hot encode target values
    trainY = to_categorical(trainY)
    testY = to_categorical(testY)
    return trainX, trainY, testX, testY

trainX, trainY, testX, testY = load_dataset()
input_shape = (28, 28, 1)

# scale pixels
def prep_pixels(train, test):
    # convert from integers to floats
    # Making sure that the values are float so that we can get decimal points after division
    train_norm = train.astype('float32')
    test_norm = test.astype('float32')
    # normalize to range 0-1
    # Normalizing the grey scale codes by dividing it by the max grey scale value.
    train_norm = train_norm / 255.0
    test_norm = test_norm / 255.0
    # return normalized images
    return train_norm, test_norm

trainX, testX = prep_pixels(trainX, testX)

# deep learning models are created where an instance of the Sequential class is created
# model layers are created and added to it.
model = Sequential() 

# 28 filters, each being size of 3x3 and slides through the image  with a stride of magnitude 1 in horizontal and vertical direction using ReLU activation function
model.add(Conv2D(28, kernel_size=(3,3), strides=(1,1), input_shape=input_shape)) 

#adding batch normalization to changing the distribution by standarising the output
model.add(BatchNormalization())

#max pooling to extract digit features
model.add(MaxPooling2D(pool_size=(2,2)))

#increasing the model depth
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1,1)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1,1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
#turns matrix values into a single vector
model.add(Flatten()) 
#hidden layer with 200 nodes and relu activation function
model.add(Dense(200,activation = "relu")) 
# dropout regularization to drop certain neurons to reduce overfitting
model.add(Dropout(0.3)) 
#adding batch normalization to changing the distribution by standarising the output
model.add(BatchNormalization())
#output layer for classification values of digits 0-9
model.add(Dense(10,activation = "softmax"))
# compile model
model.compile(optimizer="adam", loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(trainX, trainY, epochs=10, validation_data=(testX, testY))

model.evaluate(testX, testY, verbose=0)

