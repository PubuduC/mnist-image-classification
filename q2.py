# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bXI9s-TJucihSF6WRfM-9pt6vNBtEKvB
"""

from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense, BatchNormalization
from keras.optimizers import SGD
from statistics import *
import numpy as np

# load train and test dataset
def load_dataset():
    # load dataset
    (trainX, trainY), (testX, testY) = mnist.load_data()
    # reshape dataset to have a single channel
    #the pixel values are grayscale, the pixel dimension is set to 1.
    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
    testX = testX.reshape((testX.shape[0], 28, 28, 1))
    # one hot encode target values
    trainY = to_categorical(trainY)
    testY = to_categorical(testY)
    return trainX, trainY, testX, testY

trainX, trainY, testX, testY = load_dataset()
input_shape = (28, 28, 1)

# scale pixels
def prep_pixels(train, test):
    # convert from integers to floats
    # Making sure that the values are float so that we can get decimal points after division
    train_norm = train.astype('float32')
    test_norm = test.astype('float32')
    # normalize to range 0-1
    # Normalizing the grey scale codes by dividing it by the max grey scale value.
    train_norm = train_norm / 255.0
    test_norm = test_norm / 255.0
    # return normalized images
    return train_norm, test_norm

trainX, testX = prep_pixels(trainX, testX)

def generate_noise_data(noise_factor):
    x_train_noisy = trainX+ noise_factor * np.random.normal(loc=0.0, scale=1.0, size=trainX.shape)
    x_test_noisy = testX + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=testX.shape)
    x_train_noisy = np.clip(x_train_noisy, 0., 1.)
    x_test_noisy = np.clip(x_test_noisy, 0., 1.)
    return x_train_noisy, x_test_noisy

def model_build_fit_evaluate(x_train_noisy, x_test_noisy, trainY, testY):
    # deep learning models are created where an instance of the Sequential class is created
    # model layers are created and added to it.
    model = Sequential() 

    # 28 filters, each being size of 3x3 and slides through the image  with a stride of magnitude 1 in horizontal and vertical direction using ReLU activation function
    model.add(Conv2D(28, kernel_size=(3,3), strides=(1,1), input_shape=input_shape)) 

    #adding batch normalization to changing the distribution by standarising the output
    model.add(BatchNormalization())

    #max pooling to extract digit features
    model.add(MaxPooling2D(pool_size=(2,2)))

    #increasing the model depth
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1,1)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1,1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    #turns matrix values into a single vector
    model.add(Flatten()) 
    #hidden layer with 200 nodes and relu activation function
    model.add(Dense(200,activation = "relu")) 
    # dropout regularization to drop certain neurons to reduce overfitting
    model.add(Dropout(0.3)) 
    #adding batch normalization to changing the distribution by standarising the output
    model.add(BatchNormalization())
    #output layer for classification values of digits 0-9
    model.add(Dense(10,activation = "softmax"))
    # compile model
    model.compile(optimizer="adam", loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(x_train_noisy, trainY, epochs=10, validation_data=(x_test_noisy, testY))
    model.evaluate(x_test_noisy, testY, verbose=0)

noise_factor = 0.1
x_train_noisy_new, x_test_noisy_new = generate_noise_data(noise_factor)
model_build_fit_evaluate(x_train_noisy_new, x_test_noisy_new, trainY, testY)

noise_factor = 0.25
x_train_noisy_new, x_test_noisy_new = generate_noise_data(noise_factor)
model_build_fit_evaluate(x_train_noisy_new, x_test_noisy_new, trainY, testY)

noise_factor = 0.50
x_train_noisy_new, x_test_noisy_new = generate_noise_data(noise_factor)
model_build_fit_evaluate(x_train_noisy_new, x_test_noisy_new, trainY, testY)

noise_factor = 0.75
x_train_noisy_new, x_test_noisy_new = generate_noise_data(noise_factor)
model_build_fit_evaluate(x_train_noisy_new, x_test_noisy_new, trainY, testY)